{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270916d1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d48584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52056afa",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23b878fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset from AskMen and AskWomen subreddit\n",
    "df = pd.read_csv('./Datasets/askmen_top.csv')\n",
    "df2 = pd.read_csv('./Datasets/askwomen_top.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2146753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dataframe display to show full text \n",
    "pd.set_option('display.max_colwidth', 10000)\n",
    "pd.set_option('display.max_columns',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3764fb6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# return only columns required and assign new variables\n",
    "askwomen = df2[['title','subreddit','selftext']]\n",
    "askmen = df[['title','subreddit','selftext']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a2a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get shape of askmen dataframe\n",
    "askmen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8c8de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get shape of askwomen dataframe\n",
    "askwomen.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3ca81",
   "metadata": {},
   "source": [
    "## Combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42786b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine into one dataframe\n",
    "df = pd.concat([askwomen, askmen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb866fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reminder: Trans women are women. If you see transphobic commentary on this subreddit, please report</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Recently, we've seen an uptick in transphobic commentary.  We wanted to take this time to reiterate our commitment to trans women feeling welcome here.  It's askwomen policy that trans women are women, full stop, no qualifiers.  So if you see transphobic commentary, please report it.  And we will continue to not allow bigotry in this subreddit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A new dating app is launched. Instead of a photo of a person, it shows you a photo of their bedroom, car, kitchen, shoes, how they have their tea/coffee, things like that... what photo would tell you the most about someone, and would you be most interested to see to choose a potential date?</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When Kamala Harris said ‚ÄòI am speaking‚Äô while she was being interrupted over and over, how did that resonate with you?</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>Sorry guys - this post has gotten traction because it resonated with a lot of people but the mods have locked it indefinitely. \\n\\nI posted this question to understand what a moment felt for many women after I saw my own sister wince. It‚Äôs small question but the response has been powerful. I feel a lot of people can be heard and a lot of people like myself can learn.  \\n\\nHopefully if they open this sooner rather than later, we can hear more experiences and comments geared towards the question in hand. I am not sure exactly why this question in particular has been locked for this long.\\n\\nEdit 2: it‚Äôs been a month and it‚Äôs looking like this post was locked because of its content as opposed to clearing out any comments as the mods have suggested. Wonder if they had an issue with the question or the Kamala Harris?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                 title  \\\n",
       "0                                                                                                                                                                                                  Reminder: Trans women are women. If you see transphobic commentary on this subreddit, please report   \n",
       "1  A new dating app is launched. Instead of a photo of a person, it shows you a photo of their bedroom, car, kitchen, shoes, how they have their tea/coffee, things like that... what photo would tell you the most about someone, and would you be most interested to see to choose a potential date?   \n",
       "2                                                                                                                                                                               When Kamala Harris said ‚ÄòI am speaking‚Äô while she was being interrupted over and over, how did that resonate with you?   \n",
       "\n",
       "  subreddit  \\\n",
       "0  AskWomen   \n",
       "1  AskWomen   \n",
       "2  AskWomen   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  selftext  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Recently, we've seen an uptick in transphobic commentary.  We wanted to take this time to reiterate our commitment to trans women feeling welcome here.  It's askwomen policy that trans women are women, full stop, no qualifiers.  So if you see transphobic commentary, please report it.  And we will continue to not allow bigotry in this subreddit.  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      NaN  \n",
       "2  Sorry guys - this post has gotten traction because it resonated with a lot of people but the mods have locked it indefinitely. \\n\\nI posted this question to understand what a moment felt for many women after I saw my own sister wince. It‚Äôs small question but the response has been powerful. I feel a lot of people can be heard and a lot of people like myself can learn.  \\n\\nHopefully if they open this sooner rather than later, we can hear more experiences and comments geared towards the question in hand. I am not sure exactly why this question in particular has been locked for this long.\\n\\nEdit 2: it‚Äôs been a month and it‚Äôs looking like this post was locked because of its content as opposed to clearing out any comments as the mods have suggested. Wonder if they had an issue with the question or the Kamala Harris?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view dataframe\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02cac15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# replace nans with blank \n",
    "df.fillna(\"\",inplace=True)\n",
    "# combine all text into one column\n",
    "df['combined'] = df['title'] +\" \"+ df['selftext']\n",
    "# remove columns that are no longer in use\n",
    "df.drop(columns=['title', 'selftext'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e95a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit    0\n",
       "combined     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d40bb1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AskMen      0.5\n",
       "AskWomen    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data for ratio between the 2 subreddits\n",
    "df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c945cb3",
   "metadata": {},
   "source": [
    "## Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1186ea6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to convert a raw review to a string of words\n",
    "# The input is a single string (a raw post), and \n",
    "# the output is a single string (a preprocessed post)\n",
    "  \n",
    "def review_to_words(raw_review):\n",
    "    \n",
    "    # 1. Remove HTML.\n",
    "    review_text = BeautifulSoup(raw_review).get_text()\n",
    "    \n",
    "    # 2. Remove non-letters and https\n",
    "    letters_only = re.sub(\"[^a-zA-Z]|https\", \" \", review_text)\n",
    "    \n",
    "    # 4. Convert to lower case, split into individual words.\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # 5. In Python, searching a set is much faster than searching a list, so convert the stopwords to a set.\n",
    "    stops = set(stopwords.words('english') \n",
    "    others = ['women','men','ladies','guys','men','reddit'])\n",
    "    \n",
    "    # 6. Remove stopwords.\n",
    "    meaningful_words = [w for w in words if w not in stops]\n",
    "    \n",
    "    # 7. Join the words back into one string separated by space, and return the result.\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "630977d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check: check stopwords to see what has been removed\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61924536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to hold the clean reviews.\n",
    "clean_train_data = []\n",
    "\n",
    "# For every review in our training set...\n",
    "for train_data in df['combined']:\n",
    "    \n",
    "    # Convert review to words, then append to clean_train_reviews.\n",
    "    clean_train_data.append(review_to_words(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b302b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reminder trans see transphobic commentary subreddit please report recently seen uptick transphobic commentary wanted take time reiterate commitment trans feeling welcome askwomen policy trans full stop qualifiers see transphobic commentary please report continue allow bigotry subreddit'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c46fec",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f306ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate object of class PorterStemmer.\n",
    "#stem_word = nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "#for index, review in enumerate(clean_train_data):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "#    tokenization = nltk.word_tokenize(review)\n",
    "#    stemreview = \"\"\n",
    "#    for w in tokenization:\n",
    "#            stemreview = stemreview + \" \" + stem_word.stem(w)\n",
    "#    clean_train_data[index]=stemreview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d52bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "438edaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stem_word.stem('fairly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffb725c",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "475d09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):    # if pos tag starts with J, word is an adjective \n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):  # if pos tag starts with V, word is a verb\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):  # if pos tag starts with N, word is a noun\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):  # if pos tag starts with R, word is an adverb\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7488095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_data(df):\n",
    "    # instantiate WordNetLetmmatizer\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    for index, post in enumerate(clean_train_data):\n",
    "        # tokenize the sentence and find the POS tag for each token\n",
    "        tokenization = nltk.pos_tag(nltk.word_tokenize(post))\n",
    "        # replace tuple(token, pos_tag) pos tag with wordnet tag\n",
    "        wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), tokenization)\n",
    "        # create empty string\n",
    "        lemmapost = \"\"\n",
    "        for word, tag in wordnet_tagged:\n",
    "            if tag is None:\n",
    "                #if there is no available tag, append the token as is\n",
    "                lemmapost = lemmapost + \" \" + word\n",
    "            else:        \n",
    "                #else use the tag to lemmatize the token\n",
    "                lemmapost = lemmapost + \" \" + wordnet_lemmatizer.lemmatize(word,tag)\n",
    "        df[index]=lemmapost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c9741c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize_data(clean_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "78f6f80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "9d006dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_fit = cv.fit_transform(clean_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "de8040e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_words = pd.DataFrame(cv_fit.toarray().sum(axis=0).tolist(), cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "7bbae2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6340, 1)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "c563a5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feel</th>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edit</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>really</th>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friend</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "like    801\n",
       "get     714\n",
       "feel    680\n",
       "make    526\n",
       "go      503\n",
       "know    469\n",
       "want    444\n",
       "time    439\n",
       "thing   410\n",
       "say     402\n",
       "think   400\n",
       "life    377\n",
       "edit    375\n",
       "people  366\n",
       "would   362\n",
       "one     353\n",
       "really  311\n",
       "friend  299\n",
       "work    288\n",
       "year    262"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_words.sort_values(by=0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "3ec27eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaand</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaam</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdomen</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abnormal</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zodiac</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoneeeee</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwfnsr</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4331 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "aaaaand   1\n",
       "aaaam     1\n",
       "ab        1\n",
       "abdomen   1\n",
       "abnormal  2\n",
       "...      ..\n",
       "zip       1\n",
       "zodiac    1\n",
       "zoneeeee  1\n",
       "zoom      1\n",
       "zwfnsr    1\n",
       "\n",
       "[4331 rows x 1 columns]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_frequent_words[most_frequent_words[0]<4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb5eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88cd7e29",
   "metadata": {},
   "source": [
    "## Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c3ca494",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_train_data\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abdc91cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    stratify = y,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9e3fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a442ec2",
   "metadata": {},
   "source": [
    "## CVEC LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "06b810f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcvecpipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter =1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "b6bf919b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('lr', LogisticRegression(max_iter=1000, random_state=42))],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'lr': LogisticRegression(max_iter=1000, random_state=42),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'lr__C': 1.0,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 1000,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': 42,\n",
       " 'lr__solver': 'lbfgs',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False}"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcvecpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "dc425e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcvecpipe_params={'cvec__max_df': [0.3,0.5],\n",
    "                 'cvec__max_features': [2000, 3000, 4000],\n",
    "                 'cvec__min_df': [2, 3, 4],\n",
    "                 'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "                 'lr__C': [1.0, 2.0, 3.0],\n",
    "                 'lr__penalty': ['l1', 'l2'],\n",
    "                 'lr__solver': ['liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "7334608e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lrcvecgs = GridSearchCV(\n",
    "     lrcvecpipe, # what object are we optimizing?\n",
    "     param_grid = lrcvecpipe_params,\n",
    "     cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "b71ff03b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=42))]),\n",
       "             param_grid={'cvec__max_df': [0.3, 0.5],\n",
       "                         'cvec__max_features': [2000, 3000, 4000],\n",
       "                         'cvec__min_df': [2, 3, 4],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'lr__C': [1.0, 2.0, 3.0], 'lr__penalty': ['l1', 'l2'],\n",
       "                         'lr__solver': ['liblinear']})"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcvecgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "fc8d802e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7426666666666666"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcvecgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "79634b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 3000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'lr__C': 1.0,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcvecgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "26c33d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcvecgs_bestmodel = cvecgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "de5e3e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9606666666666667"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcvecgs_bestmodel.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "bace3183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.724"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrcvecgs_bestmodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "7b8030cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44703243, -0.25006734,  0.18507402, ..., -0.23263004,\n",
       "         0.07860233, -0.11288913]])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get coefficients of X variables from logistic regression \n",
    "lrcvecgs_bestmodel['lr'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "1700c9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrcveccoef = pd.DataFrame(lrcvecgs_bestmodel['lr'].coef_, columns = lrcvecgs_bestmodel['cvec'].get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "43281feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>look like</th>\n",
       "      <td>1.010722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online</th>\n",
       "      <td>0.983756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell difference</th>\n",
       "      <td>0.956278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.946386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>0.943653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <td>0.891403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>0.877732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>0.864421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.857754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority</th>\n",
       "      <td>0.841509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marry</th>\n",
       "      <td>0.823602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cry</th>\n",
       "      <td>0.807624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>0.798111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cave</th>\n",
       "      <td>0.794238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behavior</th>\n",
       "      <td>0.777719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choose</th>\n",
       "      <td>0.771741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>0.769991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughout day</th>\n",
       "      <td>0.768922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everyone</th>\n",
       "      <td>0.765907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marriage</th>\n",
       "      <td>0.753243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "look like        1.010722\n",
       "online           0.983756\n",
       "tell difference  0.956278\n",
       "mean             0.946386\n",
       "career           0.943653\n",
       "partner          0.891403\n",
       "song             0.877732\n",
       "hair             0.864421\n",
       "positive         0.857754\n",
       "majority         0.841509\n",
       "marry            0.823602\n",
       "cry              0.807624\n",
       "beautiful        0.798111\n",
       "cave             0.794238\n",
       "behavior         0.777719\n",
       "choose           0.771741\n",
       "group            0.769991\n",
       "throughout day   0.768922\n",
       "everyone         0.765907\n",
       "marriage         0.753243"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients for ask women\n",
    "lrcveccoef.sort_values(ascending=False, by=0).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d612e5f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>turn</th>\n",
       "      <td>-0.910324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>-0.914292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>-0.932124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>-0.983104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>female friend</th>\n",
       "      <td>-0.988178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand</th>\n",
       "      <td>-1.013843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit</th>\n",
       "      <td>-1.034970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seem</th>\n",
       "      <td>-1.076046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pee</th>\n",
       "      <td>-1.091647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dude</th>\n",
       "      <td>-1.103211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honest</th>\n",
       "      <td>-1.114406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothing</th>\n",
       "      <td>-1.116239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>-1.215481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>-1.234419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mine</th>\n",
       "      <td>-1.241153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsfw</th>\n",
       "      <td>-1.270344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attractive</th>\n",
       "      <td>-1.305469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>-1.319086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girlfriend</th>\n",
       "      <td>-1.389897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>-1.556592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "turn          -0.910324\n",
       "ask           -0.914292\n",
       "type          -0.932124\n",
       "male          -0.983104\n",
       "female friend -0.988178\n",
       "understand    -1.013843\n",
       "shit          -1.034970\n",
       "seem          -1.076046\n",
       "pee           -1.091647\n",
       "dude          -1.103211\n",
       "honest        -1.114406\n",
       "nothing       -1.116239\n",
       "example       -1.215481\n",
       "fuck          -1.234419\n",
       "mine          -1.241153\n",
       "nsfw          -1.270344\n",
       "attractive    -1.305469\n",
       "girl          -1.319086\n",
       "girlfriend    -1.389897\n",
       "advice        -1.556592"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coefficients for ask men\n",
    "lrcveccoef.sort_values(ascending=False, by=0).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24392fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create functions to find posts with keyword\n",
    "def review_with_word(word, lst):\n",
    "    all_reviews = []\n",
    "    for post in lst:\n",
    "        if len(re.findall(f\"\\s{word}\\W\", post))> 0:\n",
    "            all_reviews.append(post)\n",
    "    return pd.DataFrame(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc3b8b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30cd8665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where do you draw the line between ‚Äúfollowing your dreams‚Äù and being realistic about career, relationships etc?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Guys named Drew, what did you draw? Thank you, Drews! üöÄ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's your favourite type of fish? If you can draw it's that's a bonus. \\n\\nCrustaceans and other marine wildlife are also accepted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Married men, how much sacrifice/compromise did you make with your SO to make the relationship work/survive? I'm at the point in my life where my friends are getting married/engaged, and struggling to find where the fine line is between being whipped and making compromises. My cousin talked for years about not wanting kids but now is going to have them because his fiance wants them. \\n\\nWhere in compromise/sacrifice do you guys draw the line on what is and isn't worth it? I know it's a case by case basis, but just curious how other people feel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Guys who are good at talking to women you find attractive, how do you do it? I‚Äôm far from perfect but one of the positive things I have going for me is I have the gift of the gab. I‚Äôm good at conversation and I like to think I‚Äôm quite witty. Except...\\n\\nI have no problem talking to girls I‚Äôm not attracted to, but I have some kind of mental block when it comes to a girl I am attracted to. My mind just goes blank and I can‚Äôt think of anything to say. What usually comes out is some kind of bland comment about the weather or something and it‚Äôs just painfully awkward. In a prolonged conversation it usually gets better but I really wish I was one of those guys who could meet an attractive woman and be really funny and interesting straight off. What annoys me is I know I can be funny and interesting, but for some reason I draw a blank when it comes to girls I‚Äôm into.\\n\\nAny advice on how to fix this?\\n\\nEdit:\\n\\nShould have mentioned - yes, I know that attractive girls are people too. I‚Äôm not trying to objectify them - I know that the trick is to ‚Äújust talk to them as if they were anyone else‚Äù. My problem is in the execution of that. My mind just goes blank and I can‚Äôt think of what I would say to a normal person. It‚Äôs almost as if the normal, easy-going conversational bit of my brain just goes on holiday or something.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MOD POST: On Mental Health Sup shitlords,\\n\\nWe as moderators understand that times have been tough on everyone.  Everyone has something that they're going through that is difficult and you want to feel like you're not alone.  The good news for you is that you're all useless morons to us mods so that's comforting.\\n\\nBut coming to reddit to ask about mental health resources and how to improve your mental state is just plain stupid.  Like we get that you may think there is nowhere to turn, but there really is.  Literally any place on the internet is better than Reddit.  Reddit is a toxic shithole which will just draw you in further and make you more of an angry son of a bitch.  There's even [articles and research done on how shitty web forums are](https://scholars.org/contribution/countering-online-toxicity-and-hate-speech) and studies have shown that [anonymity like Reddit users have just make it worse](https://journals.sagepub.com/doi/10.1177/2056305116664220).  If 40% of internet users have experienced online harassment, why would you trust the internet to fix your mental health problems?  \\n\\nWe get that you want to find a place where you feel like other people are going through the same stuff that you are, and there's honestly a lot of good in that.  But there are several established factors working against you on reddit:\\n\\n1) Most people here are making shit up to get reactions out of you.\\n\\n2) If they're not making shit up, they're trying to make you as miserable as they are so they can feel better about themselves.\\n\\n3) Reddit is a toxic shithole in general.\\n\\nWhile there are definitely some people here who want to get better, the majority don't.  They don't want you to feel good.  They want you to feel miserable because they think that making other people miserable will make them feel better.  \\n\\n**So from now on, Automod will automatically remove all posts about dealing with depression, suicide, and men's mental health.  Automod will also link a series of sites that either provide direct links to mental health counselors, or will point you to sites with mental health counselors in your country.**\\n\\nInb4 \"mods don't care about mental health\": we do care about mental health deeply.  Most of us either see therapists or have seen therapists in the past.  Which is why we recognize the value in seeing someone who is ACTUALLY TRAINED to help you, instead of listening to some unqualified rando on the internet.\\n\\nLove,\\n\\nThe mods\\n\\n**tl;dr mental health posts now banned, automod will link mental health resources in the removal.**</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How should a man treat teenage girls when he's scared of them ? I am 23 and am scared of them when a cousin of mine was falsely accused of molesting a 13 year old.\\n\\nI don't want to be asshole to my cousins who come to me and I also want to draw a line .\\n\\nHow do you do that ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          0\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Where do you draw the line between ‚Äúfollowing your dreams‚Äù and being realistic about career, relationships etc? \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Guys named Drew, what did you draw? Thank you, Drews! üöÄ\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      What's your favourite type of fish? If you can draw it's that's a bonus. \\n\\nCrustaceans and other marine wildlife are also accepted\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Married men, how much sacrifice/compromise did you make with your SO to make the relationship work/survive? I'm at the point in my life where my friends are getting married/engaged, and struggling to find where the fine line is between being whipped and making compromises. My cousin talked for years about not wanting kids but now is going to have them because his fiance wants them. \\n\\nWhere in compromise/sacrifice do you guys draw the line on what is and isn't worth it? I know it's a case by case basis, but just curious how other people feel\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Guys who are good at talking to women you find attractive, how do you do it? I‚Äôm far from perfect but one of the positive things I have going for me is I have the gift of the gab. I‚Äôm good at conversation and I like to think I‚Äôm quite witty. Except...\\n\\nI have no problem talking to girls I‚Äôm not attracted to, but I have some kind of mental block when it comes to a girl I am attracted to. My mind just goes blank and I can‚Äôt think of anything to say. What usually comes out is some kind of bland comment about the weather or something and it‚Äôs just painfully awkward. In a prolonged conversation it usually gets better but I really wish I was one of those guys who could meet an attractive woman and be really funny and interesting straight off. What annoys me is I know I can be funny and interesting, but for some reason I draw a blank when it comes to girls I‚Äôm into.\\n\\nAny advice on how to fix this?\\n\\nEdit:\\n\\nShould have mentioned - yes, I know that attractive girls are people too. I‚Äôm not trying to objectify them - I know that the trick is to ‚Äújust talk to them as if they were anyone else‚Äù. My problem is in the execution of that. My mind just goes blank and I can‚Äôt think of what I would say to a normal person. It‚Äôs almost as if the normal, easy-going conversational bit of my brain just goes on holiday or something.\n",
       "5  MOD POST: On Mental Health Sup shitlords,\\n\\nWe as moderators understand that times have been tough on everyone.  Everyone has something that they're going through that is difficult and you want to feel like you're not alone.  The good news for you is that you're all useless morons to us mods so that's comforting.\\n\\nBut coming to reddit to ask about mental health resources and how to improve your mental state is just plain stupid.  Like we get that you may think there is nowhere to turn, but there really is.  Literally any place on the internet is better than Reddit.  Reddit is a toxic shithole which will just draw you in further and make you more of an angry son of a bitch.  There's even [articles and research done on how shitty web forums are](https://scholars.org/contribution/countering-online-toxicity-and-hate-speech) and studies have shown that [anonymity like Reddit users have just make it worse](https://journals.sagepub.com/doi/10.1177/2056305116664220).  If 40% of internet users have experienced online harassment, why would you trust the internet to fix your mental health problems?  \\n\\nWe get that you want to find a place where you feel like other people are going through the same stuff that you are, and there's honestly a lot of good in that.  But there are several established factors working against you on reddit:\\n\\n1) Most people here are making shit up to get reactions out of you.\\n\\n2) If they're not making shit up, they're trying to make you as miserable as they are so they can feel better about themselves.\\n\\n3) Reddit is a toxic shithole in general.\\n\\nWhile there are definitely some people here who want to get better, the majority don't.  They don't want you to feel good.  They want you to feel miserable because they think that making other people miserable will make them feel better.  \\n\\n**So from now on, Automod will automatically remove all posts about dealing with depression, suicide, and men's mental health.  Automod will also link a series of sites that either provide direct links to mental health counselors, or will point you to sites with mental health counselors in your country.**\\n\\nInb4 \"mods don't care about mental health\": we do care about mental health deeply.  Most of us either see therapists or have seen therapists in the past.  Which is why we recognize the value in seeing someone who is ACTUALLY TRAINED to help you, instead of listening to some unqualified rando on the internet.\\n\\nLove,\\n\\nThe mods\\n\\n**tl;dr mental health posts now banned, automod will link mental health resources in the removal.**\n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   How should a man treat teenage girls when he's scared of them ? I am 23 and am scared of them when a cousin of mine was falsely accused of molesting a 13 year old.\\n\\nI don't want to be asshole to my cousins who come to me and I also want to draw a line .\\n\\nHow do you do that ?"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_with_word('draw', list(df['combined']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b994971",
   "metadata": {},
   "source": [
    "## LR Tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "095d8372",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtvecpipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter =1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62ac521a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer()),\n",
       "  ('lr', LogisticRegression(max_iter=1000, random_state=42))],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'lr': LogisticRegression(max_iter=1000, random_state=42),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'lr__C': 1.0,\n",
       " 'lr__class_weight': None,\n",
       " 'lr__dual': False,\n",
       " 'lr__fit_intercept': True,\n",
       " 'lr__intercept_scaling': 1,\n",
       " 'lr__l1_ratio': None,\n",
       " 'lr__max_iter': 1000,\n",
       " 'lr__multi_class': 'auto',\n",
       " 'lr__n_jobs': None,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__random_state': 42,\n",
       " 'lr__solver': 'lbfgs',\n",
       " 'lr__tol': 0.0001,\n",
       " 'lr__verbose': 0,\n",
       " 'lr__warm_start': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtvecpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f29870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtvecpipe_params={'tvec__max_df': [0.5, 0.7],\n",
    "             'tvec__max_features': [2000, 3000, 4000],\n",
    "             'tvec__min_df': [2, 3, 4],\n",
    "             'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "             'lr__C': [1.0, 2.0, 3.0],\n",
    "             'lr__penalty': ['l1', 'l2'],\n",
    "             'lr__solver': ['liblinear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52f16cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtvecgs = GridSearchCV(\n",
    "    lrtvecpipe, # what object are we optimizing?\n",
    "    param_grid = lrtvecpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfc00e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000,\n",
       "                                                           random_state=42))]),\n",
       "             param_grid={'lr__C': [1.0, 2.0, 3.0], 'lr__penalty': ['l1', 'l2'],\n",
       "                         'lr__solver': ['liblinear'],\n",
       "                         'tvec__max_df': [0.5, 0.7],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [2, 3, 4],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtvecgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5bfdf8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 2.0,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__solver': 'liblinear',\n",
       " 'tvec__max_df': 0.5,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 3,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtvecgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cf170510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7453333333333333"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtvecgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5bb7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8e401a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtvecgs_bestmodel = tvecgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "5933106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtvecgs_bestmodel.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "6a5efa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.722"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtvecgs_bestmodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528006e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03a0b56e",
   "metadata": {},
   "source": [
    "We notice that the function 'best_estimator_' returns the best score on the train dataset. However, as we continuously tune the parameter to give the optimum best parameters, the model will start to overfit to the training data and its accuracy on the test dataset would drop. \n",
    "\n",
    "With that in mind, the 'best_estimator_' as the name suggest is only an estimate of the best paramaters for the model but not necessarily the absolute best parameter for the model to predict unseen data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "92a715a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43450737, -0.66309424,  0.22332126, ..., -0.23461423,\n",
       "         0.08088559, -0.20444509]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get coefficients of X variables from logistic regression \n",
    "lrtvecgs_bestmodel['lr'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c2a64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtveccoef = pd.DataFrame(lrtvecgs_bestmodel['lr'].coef_, columns = lrtvecgs_bestmodel['tvec'].get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d49c1e5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descr</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continued date person everyone tell break</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>favorite nonsexual activity</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stuck mile away boyfriends girlfriend pandemic meet together month two manage keep relationship go</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boundary non negotiable</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pratice self love see attractive without validation external source</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>get back together someone cheat give second chance work</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>play rpgs dm gm help safe feel welcome table especially look advice regard game player might know everyone anyone except gm table edit want thank everyone comment helpful</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>stop go gym covid make gain want gain covid belly joke</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>valentine day mega thread check thing gift food plan valentine day order avoid sea valentine galentine post one mega thread thread rule advice gift relax ask away also obviously ask relationship stuff monday look advice make sure descriptive succinct well information give good answer receive suggest sort new see well new stuff</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>vanilla sex woman sometimes feel inadequate relation kinky porn culture</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                         descr  \\\n",
       "2                                                                                                                                                                                                                                                                                                    continued date person everyone tell break   \n",
       "3                                                                                                                                                                                                                                                                                                                  favorite nonsexual activity   \n",
       "4                                                                                                                                                                                                                                           stuck mile away boyfriends girlfriend pandemic meet together month two manage keep relationship go   \n",
       "5                                                                                                                                                                                                                                                                                                                      boundary non negotiable   \n",
       "6                                                                                                                                                                                                                                                                          pratice self love see attractive without validation external source   \n",
       "..                                                                                                                                                                                                                                                                                                                                         ...   \n",
       "483                                                                                                                                                                                                                                                                                    get back together someone cheat give second chance work   \n",
       "485                                                                                                                                                                 play rpgs dm gm help safe feel welcome table especially look advice regard game player might know everyone anyone except gm table edit want thank everyone comment helpful   \n",
       "491                                                                                                                                                                                                                                                                                     stop go gym covid make gain want gain covid belly joke   \n",
       "493   valentine day mega thread check thing gift food plan valentine day order avoid sea valentine galentine post one mega thread thread rule advice gift relax ask away also obviously ask relationship stuff monday look advice make sure descriptive succinct well information give good answer receive suggest sort new see well new stuff   \n",
       "495                                                                                                                                                                                                                                                                    vanilla sex woman sometimes feel inadequate relation kinky porn culture   \n",
       "\n",
       "       actual predicted  \n",
       "2    AskWomen    AskMen  \n",
       "3      AskMen  AskWomen  \n",
       "4    AskWomen    AskMen  \n",
       "5      AskMen  AskWomen  \n",
       "6      AskMen  AskWomen  \n",
       "..        ...       ...  \n",
       "483  AskWomen    AskMen  \n",
       "485  AskWomen    AskMen  \n",
       "491    AskMen  AskWomen  \n",
       "493  AskWomen    AskMen  \n",
       "495  AskWomen    AskMen  \n",
       "\n",
       "[139 rows x 3 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrongly_classified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "38331fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>etc</th>\n",
       "      <td>1.623913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <td>1.609759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>1.544934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>1.489644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.294003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>1.275973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever</th>\n",
       "      <td>1.268240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tell difference</th>\n",
       "      <td>1.197554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>look like</th>\n",
       "      <td>1.193451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>online</th>\n",
       "      <td>1.181481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>1.173172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1.159304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cry</th>\n",
       "      <td>1.149280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>song</th>\n",
       "      <td>1.104238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>1.073402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friendship</th>\n",
       "      <td>1.056650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everyone</th>\n",
       "      <td>1.025899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instead</th>\n",
       "      <td>1.005491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marriage</th>\n",
       "      <td>1.003876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choose</th>\n",
       "      <td>1.002636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "etc              1.623913\n",
       "partner          1.609759\n",
       "hair             1.544934\n",
       "career           1.489644\n",
       "mean             1.294003\n",
       "best             1.275973\n",
       "ever             1.268240\n",
       "tell difference  1.197554\n",
       "look like        1.193451\n",
       "online           1.181481\n",
       "period           1.173172\n",
       "positive         1.159304\n",
       "cry              1.149280\n",
       "song             1.104238\n",
       "married          1.073402\n",
       "friendship       1.056650\n",
       "everyone         1.025899\n",
       "instead          1.005491\n",
       "marriage         1.003876\n",
       "choose           1.002636"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtveccoef.sort_values(ascending=False, by=0).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03ea8544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>-1.704197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsfw</th>\n",
       "      <td>-1.706088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turn</th>\n",
       "      <td>-1.719958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seem</th>\n",
       "      <td>-1.740754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>-1.749106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mine</th>\n",
       "      <td>-1.784945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>-1.828883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wife</th>\n",
       "      <td>-1.909598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>-1.990935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>-2.053733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>-2.073744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attractive</th>\n",
       "      <td>-2.165428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ask</th>\n",
       "      <td>-2.197043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>-2.234075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>-2.236991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>-2.367810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>-2.541616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girlfriend</th>\n",
       "      <td>-2.603972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>-2.692983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>-3.184948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "time       -1.704197\n",
       "nsfw       -1.706088\n",
       "turn       -1.719958\n",
       "seem       -1.740754\n",
       "date       -1.749106\n",
       "mine       -1.784945\n",
       "see        -1.828883\n",
       "wife       -1.909598\n",
       "go         -1.990935\n",
       "talk       -2.053733\n",
       "fuck       -2.073744\n",
       "attractive -2.165428\n",
       "ask        -2.197043\n",
       "even       -2.234075\n",
       "guy        -2.236991\n",
       "want       -2.367810\n",
       "get        -2.541616\n",
       "girlfriend -2.603972\n",
       "advice     -2.692983\n",
       "girl       -3.184948"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtveccoef.sort_values(ascending=False, by=0).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c19d84",
   "metadata": {},
   "source": [
    "#### KNN Classifier Cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fe9033",
   "metadata": {},
   "source": [
    "The KNN has scored the worst amongst a series of tests done on different models. With that in mind, I have sought to deep dive into the parameter tuning to see if we can get significant improvement to the KNN accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31395904",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncvecpipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db811c2c",
   "metadata": {},
   "source": [
    "In deterimining the parameters for the KNN classifier, we will exclude the Euclidean distance because it is a oversimplified distance measuring technique that may not do well with multidimensional and sparse data. Further readings, can be looked at [here](https://stats.stackexchange.com/questions/29627/euclidean-distance-is-usually-not-good-for-sparse-data-and-more-general-case).\n",
    "\n",
    "To test, I have used the same pipe parameters over different knn metrics: \n",
    "1. The Eucliladean metric\n",
    "    best score : 0.55  \n",
    "    train score : 0.71   \n",
    "    test score : 0.53\n",
    "    \n",
    "2. The Manhattan metric\n",
    "    best score : 0.54  \n",
    "    train score : 0.698   \n",
    "    test score : 0.472\n",
    "    \n",
    "3. The Minkowski metric\n",
    "    best score : 0.55  \n",
    "    train score : 0.997   \n",
    "    test score : 0.53\n",
    "\n",
    "From this test we can see that the best overall metric is the Minkowski metric. However, the KNN seems to score fairly bad in all different types of metric and hence, may not be the best model for our dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca069cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncvecpipe_params={'knn__leaf_size': [10,30,50],\n",
    "                    'knn__metric': ['manhattan'],\n",
    "                    'knn__n_neighbors': [5, 21, 35],\n",
    "                    'knn__weights': ['uniform', 'distance'],\n",
    "                    'cvec__max_df': [0.3,0.5],\n",
    "                    'cvec__max_features': [1000, 2000, 3000],\n",
    "                    'cvec__min_df': [2, 3, 4],\n",
    "                    'cvec__ngram_range': [(1, 1), (1, 2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fcc6232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncvecpipe_params2={'knn__leaf_size': [10,30,50],\n",
    "                    'knn__metric': ['minkowski'],\n",
    "                    'knn__n_neighbors': [5, 21, 35],\n",
    "                    'knn__weights': ['uniform', 'distance'],\n",
    "                    'cvec__max_df': [0.3,0.5],\n",
    "                    'cvec__max_features': [1000, 2000, 3000],\n",
    "                    'cvec__min_df': [2, 3, 4],\n",
    "                    'cvec__ngram_range': [(1, 1), (1, 2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0a67f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncvecgs = GridSearchCV(\n",
    "    knncvecpipe, # what object are we optimizing?\n",
    "    param_grid = knncvecpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd3d6276",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncvecgs2 = GridSearchCV(\n",
    "    knncvecpipe, # what object are we optimizing?\n",
    "    param_grid = knncvecpipe_params2,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2e6cfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.3, 0.5],\n",
       "                         'cvec__max_features': [1000, 2000, 3000],\n",
       "                         'cvec__min_df': [2, 3, 4],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'knn__leaf_size': [10, 30, 50],\n",
       "                         'knn__metric': ['manhattan'],\n",
       "                         'knn__n_neighbors': [5, 21, 35],\n",
       "                         'knn__weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9e522ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.3, 0.5],\n",
       "                         'cvec__max_features': [1000, 2000, 3000],\n",
       "                         'cvec__min_df': [2, 3, 4],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'knn__leaf_size': [10, 30, 50],\n",
       "                         'knn__metric': ['minkowski'],\n",
       "                         'knn__n_neighbors': [5, 21, 35],\n",
       "                         'knn__weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a950477a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5433333333333333"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87cf0647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553333333333332"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fc026d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 4,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'knn__leaf_size': 10,\n",
       " 'knn__metric': 'manhattan',\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c392dad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 3,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'knn__leaf_size': 10,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__n_neighbors': 21,\n",
       " 'knn__weights': 'distance'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b75b5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncvecgs_bestmodel = knncvecgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a7be7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "knncvecgs2.bestmodel = knncvecgs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "93a39a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.698"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs_bestmodel.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "44256b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973333333333333"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs2.bestmodel.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "155ebae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.472"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs_bestmodel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb304f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knncvecgs2.bestmodel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    df['petal length (cm)'],\n",
    "    df['petal width (cm)'],\n",
    "    color = df['species'].map({0: 'red', 1: 'green', 2:'blue'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec16c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3a4d075",
   "metadata": {},
   "source": [
    "#### KNN Classifier Tfid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0cb32",
   "metadata": {},
   "source": [
    "As we have determine Minkowski to be the best metric above, we will use the SKlearn default metric of the KNNClassifier here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "99d2a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "knntfidpipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a867e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer()), ('knn', KNeighborsClassifier())],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'knn': KNeighborsClassifier(),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'knn__algorithm': 'auto',\n",
       " 'knn__leaf_size': 30,\n",
       " 'knn__metric': 'minkowski',\n",
       " 'knn__metric_params': None,\n",
       " 'knn__n_jobs': None,\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 2,\n",
       " 'knn__weights': 'uniform'}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knntfidpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fdba7d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knntfidpipe_params={'knn__n_neighbors': [5, 21, 35],\n",
    "             'knn__leaf_size': [10,30],\n",
    "             'knn__weights': ['distance', 'uniform'],\n",
    "             'tvec__max_df': [0.5, 0.7],\n",
    "             'tvec__max_features': [2000],\n",
    "             'tvec__min_df': [3, 4, 5],\n",
    "             'tvec__ngram_range': [(1, 2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "632e896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knntfidgs = GridSearchCV(\n",
    "    knntfidpipe, # what object are we optimizing?\n",
    "    param_grid = knntfidpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "23c6272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'knn__leaf_size': [10, 30],\n",
       "                         'knn__n_neighbors': [5, 21, 35],\n",
       "                         'knn__weights': ['distance', 'uniform'],\n",
       "                         'tvec__max_df': [0.5, 0.7],\n",
       "                         'tvec__max_features': [2000],\n",
       "                         'tvec__min_df': [3, 4, 5],\n",
       "                         'tvec__ngram_range': [(1, 2)]})"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knntfidgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8cfc77e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__leaf_size': 10,\n",
       " 'knn__n_neighbors': 21,\n",
       " 'knn__weights': 'distance',\n",
       " 'tvec__max_df': 0.5,\n",
       " 'tvec__max_features': 2000,\n",
       " 'tvec__min_df': 3,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knntfidgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e2775908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.712"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knntfidgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4c1515ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "knntfidgs_bestmodel = knntfidgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d0f28745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9986666666666667"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knntfidgs_bestmodel.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d939cdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knntfidgs_bestmodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38ed48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7218b915",
   "metadata": {},
   "source": [
    "We conclude from our tests that KNN is not a good model, even when using Tfid vectorizer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fe76a",
   "metadata": {},
   "source": [
    "#### Naive Baynes Tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ccbd0f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidpipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "76287251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer()), ('nb', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'nb': MultinomialNB(),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'nb__alpha': 1.0,\n",
       " 'nb__class_prior': None,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7da9ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidpipe_params={\n",
    "             'tvec__max_df': [0.3,0.5],\n",
    "             'tvec__max_features': [2000, 3000],\n",
    "             'tvec__min_df': [3, 4, 5],\n",
    "             'tvec__ngram_range': [(1, 1),(1, 2)],\n",
    "             'nb__alpha': [1.0,2.0,3.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a18e55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidpipe_params2={\n",
    "             'tvec__max_df': [0.15,0.5],\n",
    "             'tvec__max_features': [1000, 2000, 3000],\n",
    "             'tvec__min_df': [3, 4, 5],\n",
    "             'tvec__ngram_range': [(1, 1),(1, 2)],\n",
    "             'nb__alpha': [1.0,2.0,3.0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ea815",
   "metadata": {},
   "source": [
    "After tuning several models, we realize that the max_df doesn't improve the score at all after a certain threshold (in our case, this threshold is 0.3). With that in mind, we will keep max_df as 0.3 for all models and set 0.5 as an option in cases where this might not stand true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ded93cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidgs = GridSearchCV(\n",
    "    nbtfidpipe, # what object are we optimizing?\n",
    "    param_grid = nbtfidpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "7029856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidgs2 = GridSearchCV(\n",
    "    nbtfidpipe, # what object are we optimizing?\n",
    "    param_grid = nbtfidpipe_params2,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "8bc40b04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'nb__alpha': [1.0, 2.0, 3.0],\n",
       "                         'tvec__max_df': [0.3, 0.5],\n",
       "                         'tvec__max_features': [2000, 3000],\n",
       "                         'tvec__min_df': [3, 4, 5],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5db673db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'nb__alpha': [1.0, 2.0, 3.0],\n",
       "                         'tvec__max_df': [0.15, 0.5],\n",
       "                         'tvec__max_features': [1000, 2000, 3000],\n",
       "                         'tvec__min_df': [3, 4, 5],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ba253ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 2.0,\n",
       " 'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': 2000,\n",
       " 'tvec__min_df': 4,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "dfd1e0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nb__alpha': 1.0,\n",
       " 'tvec__max_df': 0.15,\n",
       " 'tvec__max_features': 1000,\n",
       " 'tvec__min_df': 5,\n",
       " 'tvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "498d425b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166666666666667"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "17ee285b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299999999999999"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "30263a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidgs_bestmodel = nbtfidgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f22dc5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidgs_bestmodel2 = nbtfidgs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "bbdeb995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8626666666666667"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs_bestmodel.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "ffa4c50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8486666666666667"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs_bestmodel2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "93c0cc6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs_bestmodel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b4daa7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs_bestmodel2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35a48f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3928498",
   "metadata": {},
   "source": [
    "we realize that whilst the function tends to prefer a lower max_feature score, as it gives the best_score_ it might not give the best parameter for the model to perform with unseen data. With that in mind, we should be carefull when reducing max_features to prevent overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "83a792d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidgs_bestmodel_featurescoef = pd.DataFrame(nbtfidgs_bestmodel['nb'].feature_log_prob_,\n",
    "                                     columns = nbtfidgs_bestmodel['tvec'].get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "02691c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbtfidgs_bestmodel_featurescoef['difference'] = nbtfidgs_bestmodel_featurescoef[0] - nbtfidgs_bestmodel_featurescoef[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "bfe633ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " nbtfidgs_bestmodel_featurescoef['abs'] = abs(nbtfidgs_bestmodel_featurescoef[0]) - abs(nbtfidgs_bestmodel_featurescoef[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "e9f3abc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>difference</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>illness</th>\n",
       "      <td>-8.000730</td>\n",
       "      <td>-6.897895</td>\n",
       "      <td>-1.102836</td>\n",
       "      <td>1.102836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>-7.482818</td>\n",
       "      <td>-6.401711</td>\n",
       "      <td>-1.081106</td>\n",
       "      <td>1.081106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.069798</td>\n",
       "      <td>-0.991246</td>\n",
       "      <td>0.991246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>-7.548769</td>\n",
       "      <td>-6.563307</td>\n",
       "      <td>-0.985462</td>\n",
       "      <td>0.985462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quit</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.079420</td>\n",
       "      <td>-0.981623</td>\n",
       "      <td>0.981623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plot</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.099599</td>\n",
       "      <td>-0.961445</td>\n",
       "      <td>0.961445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makeup</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.139601</td>\n",
       "      <td>-0.921443</td>\n",
       "      <td>0.921443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gut</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.144314</td>\n",
       "      <td>-0.916730</td>\n",
       "      <td>0.916730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner</th>\n",
       "      <td>-6.715244</td>\n",
       "      <td>-5.800880</td>\n",
       "      <td>-0.914364</td>\n",
       "      <td>0.914364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combat</th>\n",
       "      <td>-8.013803</td>\n",
       "      <td>-7.109635</td>\n",
       "      <td>-0.904168</td>\n",
       "      <td>0.904168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurtful</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.158025</td>\n",
       "      <td>-0.903019</td>\n",
       "      <td>0.903019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>career</th>\n",
       "      <td>-7.190636</td>\n",
       "      <td>-6.299891</td>\n",
       "      <td>-0.890744</td>\n",
       "      <td>0.890744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>-7.844195</td>\n",
       "      <td>-6.954648</td>\n",
       "      <td>-0.889547</td>\n",
       "      <td>0.889547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loneliness</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.182059</td>\n",
       "      <td>-0.878984</td>\n",
       "      <td>0.878984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spouse</th>\n",
       "      <td>-7.975262</td>\n",
       "      <td>-7.100082</td>\n",
       "      <td>-0.875180</td>\n",
       "      <td>0.875180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>-8.061044</td>\n",
       "      <td>-7.193635</td>\n",
       "      <td>-0.867409</td>\n",
       "      <td>0.867409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wedding</th>\n",
       "      <td>-8.021630</td>\n",
       "      <td>-7.183752</td>\n",
       "      <td>-0.837878</td>\n",
       "      <td>0.837878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etc</th>\n",
       "      <td>-6.833878</td>\n",
       "      <td>-6.010275</td>\n",
       "      <td>-0.823604</td>\n",
       "      <td>0.823604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deeply</th>\n",
       "      <td>-7.975611</td>\n",
       "      <td>-7.156420</td>\n",
       "      <td>-0.819192</td>\n",
       "      <td>0.819192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rise</th>\n",
       "      <td>-7.964559</td>\n",
       "      <td>-7.146593</td>\n",
       "      <td>-0.817967</td>\n",
       "      <td>0.817967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1  difference       abs\n",
       "illness    -8.000730 -6.897895   -1.102836  1.102836\n",
       "hair       -7.482818 -6.401711   -1.081106  1.081106\n",
       "item       -8.061044 -7.069798   -0.991246  0.991246\n",
       "period     -7.548769 -6.563307   -0.985462  0.985462\n",
       "quit       -8.061044 -7.079420   -0.981623  0.981623\n",
       "plot       -8.061044 -7.099599   -0.961445  0.961445\n",
       "makeup     -8.061044 -7.139601   -0.921443  0.921443\n",
       "gut        -8.061044 -7.144314   -0.916730  0.916730\n",
       "partner    -6.715244 -5.800880   -0.914364  0.914364\n",
       "combat     -8.013803 -7.109635   -0.904168  0.904168\n",
       "hurtful    -8.061044 -7.158025   -0.903019  0.903019\n",
       "career     -7.190636 -6.299891   -0.890744  0.890744\n",
       "impact     -7.844195 -6.954648   -0.889547  0.889547\n",
       "loneliness -8.061044 -7.182059   -0.878984  0.878984\n",
       "spouse     -7.975262 -7.100082   -0.875180  0.875180\n",
       "asian      -8.061044 -7.193635   -0.867409  0.867409\n",
       "wedding    -8.021630 -7.183752   -0.837878  0.837878\n",
       "etc        -6.833878 -6.010275   -0.823604  0.823604\n",
       "deeply     -7.975611 -7.156420   -0.819192  0.819192\n",
       "rise       -7.964559 -7.146593   -0.817967  0.817967"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs_bestmodel_featurescoef.sort_values(by='difference').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "08054158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>difference</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nothing</th>\n",
       "      <td>-6.805076</td>\n",
       "      <td>-7.591490</td>\n",
       "      <td>0.786414</td>\n",
       "      <td>-0.786414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>-6.807170</td>\n",
       "      <td>-7.601870</td>\n",
       "      <td>0.794701</td>\n",
       "      <td>-0.794701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boy</th>\n",
       "      <td>-7.021050</td>\n",
       "      <td>-7.827088</td>\n",
       "      <td>0.806038</td>\n",
       "      <td>-0.806038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <td>-6.962598</td>\n",
       "      <td>-7.812975</td>\n",
       "      <td>0.850377</td>\n",
       "      <td>-0.850377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit</th>\n",
       "      <td>-6.915852</td>\n",
       "      <td>-7.777658</td>\n",
       "      <td>0.861806</td>\n",
       "      <td>-0.861806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretty</th>\n",
       "      <td>-6.810544</td>\n",
       "      <td>-7.708348</td>\n",
       "      <td>0.897805</td>\n",
       "      <td>-0.897805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>talk</th>\n",
       "      <td>-6.007496</td>\n",
       "      <td>-6.931273</td>\n",
       "      <td>0.923777</td>\n",
       "      <td>-0.923777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-6.886772</td>\n",
       "      <td>-7.822063</td>\n",
       "      <td>0.935292</td>\n",
       "      <td>-0.935292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gf</th>\n",
       "      <td>-6.906866</td>\n",
       "      <td>-7.862169</td>\n",
       "      <td>0.955303</td>\n",
       "      <td>-0.955303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mine</th>\n",
       "      <td>-6.874215</td>\n",
       "      <td>-7.862169</td>\n",
       "      <td>0.987954</td>\n",
       "      <td>-0.987954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>-6.092324</td>\n",
       "      <td>-7.098907</td>\n",
       "      <td>1.006584</td>\n",
       "      <td>-1.006584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dude</th>\n",
       "      <td>-6.853473</td>\n",
       "      <td>-7.862169</td>\n",
       "      <td>1.008696</td>\n",
       "      <td>-1.008696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attractive</th>\n",
       "      <td>-6.573390</td>\n",
       "      <td>-7.603363</td>\n",
       "      <td>1.029973</td>\n",
       "      <td>-1.029973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>-6.704155</td>\n",
       "      <td>-7.789585</td>\n",
       "      <td>1.085430</td>\n",
       "      <td>-1.085430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wife</th>\n",
       "      <td>-6.534857</td>\n",
       "      <td>-7.628232</td>\n",
       "      <td>1.093374</td>\n",
       "      <td>-1.093374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>-6.607025</td>\n",
       "      <td>-7.734866</td>\n",
       "      <td>1.127841</td>\n",
       "      <td>-1.127841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advice</th>\n",
       "      <td>-6.234295</td>\n",
       "      <td>-7.423088</td>\n",
       "      <td>1.188793</td>\n",
       "      <td>-1.188793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>-5.650874</td>\n",
       "      <td>-6.927821</td>\n",
       "      <td>1.276947</td>\n",
       "      <td>-1.276947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>-6.153611</td>\n",
       "      <td>-7.544056</td>\n",
       "      <td>1.390445</td>\n",
       "      <td>-1.390445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girlfriend</th>\n",
       "      <td>-6.411996</td>\n",
       "      <td>-7.862169</td>\n",
       "      <td>1.450173</td>\n",
       "      <td>-1.450173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1  difference       abs\n",
       "nothing    -6.805076 -7.591490    0.786414 -0.786414\n",
       "play       -6.807170 -7.601870    0.794701 -0.794701\n",
       "boy        -7.021050 -7.827088    0.806038 -0.806038\n",
       "funny      -6.962598 -7.812975    0.850377 -0.850377\n",
       "shit       -6.915852 -7.777658    0.861806 -0.861806\n",
       "pretty     -6.810544 -7.708348    0.897805 -0.897805\n",
       "talk       -6.007496 -6.931273    0.923777 -0.923777\n",
       "two        -6.886772 -7.822063    0.935292 -0.935292\n",
       "gf         -6.906866 -7.862169    0.955303 -0.955303\n",
       "mine       -6.874215 -7.862169    0.987954 -0.987954\n",
       "even       -6.092324 -7.098907    1.006584 -1.006584\n",
       "dude       -6.853473 -7.862169    1.008696 -1.008696\n",
       "attractive -6.573390 -7.603363    1.029973 -1.029973\n",
       "sure       -6.704155 -7.789585    1.085430 -1.085430\n",
       "wife       -6.534857 -7.628232    1.093374 -1.093374\n",
       "fuck       -6.607025 -7.734866    1.127841 -1.127841\n",
       "advice     -6.234295 -7.423088    1.188793 -1.188793\n",
       "girl       -5.650874 -6.927821    1.276947 -1.276947\n",
       "guy        -6.153611 -7.544056    1.390445 -1.390445\n",
       "girlfriend -6.411996 -7.862169    1.450173 -1.450173"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbtfidgs_bestmodel_featurescoef.sort_values(by='difference').tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc31e1e7",
   "metadata": {},
   "source": [
    "#### NB Classifier Cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0d9fea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcvecpipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0644118c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()), ('nb', MultinomialNB())],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'nb': MultinomialNB(),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'nb__alpha': 1.0,\n",
       " 'nb__class_prior': None,\n",
       " 'nb__fit_prior': True}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "65058700",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcvecpipe_params={ 'cvec__max_df': [0.3,0.5, 0.75],\n",
    "                    'cvec__max_features': [1000, 2000, 3000],\n",
    "                    'cvec__min_df': [5, 6, 7],\n",
    "                    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "                    'nb__alpha': [1.0, 2.0, 3.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f3cb2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcvecgs = GridSearchCV(\n",
    "    nbcvecpipe, # what object are we optimizing?\n",
    "    param_grid = nbcvecpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c3a53d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.3, 0.5, 0.75],\n",
       "                         'cvec__max_features': [1000, 2000, 3000],\n",
       "                         'cvec__min_df': [5, 6, 7],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'nb__alpha': [1.0, 2.0, 3.0]})"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "db742a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 6,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'nb__alpha': 2.0}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "81c40679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7213333333333334"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4d8577e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcvecgs_bestmodel = nbcvecgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0dbc96a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246666666666667"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs_bestmodel.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c13ab202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs_bestmodel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89680f0e",
   "metadata": {},
   "source": [
    "Notice that the model does not perform very well in all 3 datasets. \n",
    "As such we will look into what are the words that causes these misclassifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f2cee0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcvecgs_bestmodel_featurescoef = pd.DataFrame(nbcvecgs_bestmodel['nb'].feature_log_prob_,\n",
    "                                     columns = nbcvecgs_bestmodel['cvec'].get_feature_names()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "35ac9c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>-7.023600</td>\n",
       "      <td>-6.892642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absolutely</th>\n",
       "      <td>-7.957909</td>\n",
       "      <td>-7.180324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>-8.409894</td>\n",
       "      <td>-7.585789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abusive</th>\n",
       "      <td>-8.158580</td>\n",
       "      <td>-6.604960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accept</th>\n",
       "      <td>-7.220310</td>\n",
       "      <td>-7.074963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yesterday</th>\n",
       "      <td>-7.583216</td>\n",
       "      <td>-8.684401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yet</th>\n",
       "      <td>-7.023600</td>\n",
       "      <td>-6.892642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>-6.800456</td>\n",
       "      <td>-6.381816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>-8.409894</td>\n",
       "      <td>-7.298107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youtube</th>\n",
       "      <td>-8.276363</td>\n",
       "      <td>-7.991254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1318 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1\n",
       "able       -7.023600 -6.892642\n",
       "absolutely -7.957909 -7.180324\n",
       "abuse      -8.409894 -7.585789\n",
       "abusive    -8.158580 -6.604960\n",
       "accept     -7.220310 -7.074963\n",
       "...              ...       ...\n",
       "yesterday  -7.583216 -8.684401\n",
       "yet        -7.023600 -6.892642\n",
       "young      -6.800456 -6.381816\n",
       "youth      -8.409894 -7.298107\n",
       "youtube    -8.276363 -7.991254\n",
       "\n",
       "[1318 rows x 2 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs_bestmodel_featurescoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "8b9e77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcvecgs_bestmodel_featurescoef['difference'] = nbcvecgs_bestmodel_featurescoef[0] - nbcvecgs_bestmodel_featurescoef[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "8f5a8d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mental illness</th>\n",
       "      <td>-9.662657</td>\n",
       "      <td>-6.738491</td>\n",
       "      <td>-2.924166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illness</th>\n",
       "      <td>-9.257192</td>\n",
       "      <td>-6.604960</td>\n",
       "      <td>-2.652233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic relationship</th>\n",
       "      <td>-9.662657</td>\n",
       "      <td>-7.298107</td>\n",
       "      <td>-2.364551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quit</th>\n",
       "      <td>-9.662657</td>\n",
       "      <td>-7.298107</td>\n",
       "      <td>-2.364551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member</th>\n",
       "      <td>-9.257192</td>\n",
       "      <td>-7.298107</td>\n",
       "      <td>-1.959085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hair</th>\n",
       "      <td>-8.053219</td>\n",
       "      <td>-6.119452</td>\n",
       "      <td>-1.933768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rise</th>\n",
       "      <td>-9.257192</td>\n",
       "      <td>-7.431638</td>\n",
       "      <td>-1.825554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spouse</th>\n",
       "      <td>-9.257192</td>\n",
       "      <td>-7.431638</td>\n",
       "      <td>-1.825554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trait</th>\n",
       "      <td>-9.257192</td>\n",
       "      <td>-7.431638</td>\n",
       "      <td>-1.825554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behaviour</th>\n",
       "      <td>-8.746367</td>\n",
       "      <td>-7.074963</td>\n",
       "      <td>-1.671403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impact</th>\n",
       "      <td>-8.746367</td>\n",
       "      <td>-7.074963</td>\n",
       "      <td>-1.671403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>askwomen</th>\n",
       "      <td>-8.564045</td>\n",
       "      <td>-6.892642</td>\n",
       "      <td>-1.671403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deeply</th>\n",
       "      <td>-8.969510</td>\n",
       "      <td>-7.298107</td>\n",
       "      <td>-1.671403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marriage</th>\n",
       "      <td>-8.564045</td>\n",
       "      <td>-6.892642</td>\n",
       "      <td>-1.671403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wish know</th>\n",
       "      <td>-8.969510</td>\n",
       "      <td>-7.298107</td>\n",
       "      <td>-1.671403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feeling like</th>\n",
       "      <td>-8.969510</td>\n",
       "      <td>-7.298107</td>\n",
       "      <td>-1.671403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever feel</th>\n",
       "      <td>-8.409894</td>\n",
       "      <td>-6.812599</td>\n",
       "      <td>-1.597295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abusive</th>\n",
       "      <td>-8.158580</td>\n",
       "      <td>-6.604960</td>\n",
       "      <td>-1.553620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lesson learn</th>\n",
       "      <td>-8.969510</td>\n",
       "      <td>-7.431638</td>\n",
       "      <td>-1.537872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistake make</th>\n",
       "      <td>-8.969510</td>\n",
       "      <td>-7.431638</td>\n",
       "      <td>-1.537872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1  difference\n",
       "mental illness        -9.662657 -6.738491   -2.924166\n",
       "illness               -9.257192 -6.604960   -2.652233\n",
       "romantic relationship -9.662657 -7.298107   -2.364551\n",
       "quit                  -9.662657 -7.298107   -2.364551\n",
       "member                -9.257192 -7.298107   -1.959085\n",
       "hair                  -8.053219 -6.119452   -1.933768\n",
       "rise                  -9.257192 -7.431638   -1.825554\n",
       "spouse                -9.257192 -7.431638   -1.825554\n",
       "trait                 -9.257192 -7.431638   -1.825554\n",
       "behaviour             -8.746367 -7.074963   -1.671403\n",
       "impact                -8.746367 -7.074963   -1.671403\n",
       "askwomen              -8.564045 -6.892642   -1.671403\n",
       "deeply                -8.969510 -7.298107   -1.671403\n",
       "marriage              -8.564045 -6.892642   -1.671403\n",
       "wish know             -8.969510 -7.298107   -1.671403\n",
       "feeling like          -8.969510 -7.298107   -1.671403\n",
       "ever feel             -8.409894 -6.812599   -1.597295\n",
       "abusive               -8.158580 -6.604960   -1.553620\n",
       "lesson learn          -8.969510 -7.431638   -1.537872\n",
       "mistake make          -8.969510 -7.431638   -1.537872"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs_bestmodel_featurescoef.sort_values(by='difference').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0cce234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>even though</th>\n",
       "      <td>-7.311282</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.373119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>husband</th>\n",
       "      <td>-7.311282</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.373119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smell</th>\n",
       "      <td>-7.264762</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.419639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kinda</th>\n",
       "      <td>-7.220310</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.464091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shit</th>\n",
       "      <td>-6.800456</td>\n",
       "      <td>-8.278936</td>\n",
       "      <td>1.478480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>-5.191018</td>\n",
       "      <td>-6.669498</td>\n",
       "      <td>1.478480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matter</th>\n",
       "      <td>-6.800456</td>\n",
       "      <td>-8.278936</td>\n",
       "      <td>1.478480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nothing</th>\n",
       "      <td>-6.505657</td>\n",
       "      <td>-7.991254</td>\n",
       "      <td>1.485597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretty</th>\n",
       "      <td>-6.484603</td>\n",
       "      <td>-7.991254</td>\n",
       "      <td>1.506651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>im</th>\n",
       "      <td>-7.136929</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.547472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conversation</th>\n",
       "      <td>-6.692243</td>\n",
       "      <td>-8.278936</td>\n",
       "      <td>1.586693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mine</th>\n",
       "      <td>-7.059968</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.624434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wife</th>\n",
       "      <td>-6.312753</td>\n",
       "      <td>-7.991254</td>\n",
       "      <td>1.678501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sure</th>\n",
       "      <td>-6.244931</td>\n",
       "      <td>-7.991254</td>\n",
       "      <td>1.746323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-6.527163</td>\n",
       "      <td>-8.278936</td>\n",
       "      <td>1.751773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dude</th>\n",
       "      <td>-6.859297</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.825104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gf</th>\n",
       "      <td>-6.800456</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>1.883945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuck</th>\n",
       "      <td>-6.385513</td>\n",
       "      <td>-8.278936</td>\n",
       "      <td>1.893423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy</th>\n",
       "      <td>-5.473003</td>\n",
       "      <td>-7.431638</td>\n",
       "      <td>1.958636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girlfriend</th>\n",
       "      <td>-6.136297</td>\n",
       "      <td>-8.684401</td>\n",
       "      <td>2.548104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1  difference\n",
       "even though  -7.311282 -8.684401    1.373119\n",
       "husband      -7.311282 -8.684401    1.373119\n",
       "smell        -7.264762 -8.684401    1.419639\n",
       "kinda        -7.220310 -8.684401    1.464091\n",
       "shit         -6.800456 -8.278936    1.478480\n",
       "girl         -5.191018 -6.669498    1.478480\n",
       "matter       -6.800456 -8.278936    1.478480\n",
       "nothing      -6.505657 -7.991254    1.485597\n",
       "pretty       -6.484603 -7.991254    1.506651\n",
       "im           -7.136929 -8.684401    1.547472\n",
       "conversation -6.692243 -8.278936    1.586693\n",
       "mine         -7.059968 -8.684401    1.624434\n",
       "wife         -6.312753 -7.991254    1.678501\n",
       "sure         -6.244931 -7.991254    1.746323\n",
       "two          -6.527163 -8.278936    1.751773\n",
       "dude         -6.859297 -8.684401    1.825104\n",
       "gf           -6.800456 -8.684401    1.883945\n",
       "fuck         -6.385513 -8.278936    1.893423\n",
       "guy          -5.473003 -7.431638    1.958636\n",
       "girlfriend   -6.136297 -8.684401    2.548104"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbcvecgs_bestmodel_featurescoef.sort_values(by='difference').tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4923d991",
   "metadata": {},
   "source": [
    "**Interesting Facts in the first run**  \n",
    "- All of the scores that we have right now are non-satisfactory, our target is to get an accuracy score of above 0.9 on the model.\n",
    "\n",
    "- The best model with the best performance is logistics regression, and the worst is the KNN model.\n",
    "\n",
    "- Overall, the TFIDF tend to perform better than the Count Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752972ed",
   "metadata": {},
   "source": [
    "The Term-Frequency-Inverse-Document Frequency may perform better as it weighs down the common words occuring in almost all the documents and give more importance to the words that appear in a subset of documents. By penalising these common words, we can reduce misclassifications. \n",
    "\n",
    "We will try to reduce words that are causing misclassifications manualls to improve the scores. To do so we will be using linear regression coefficients as a benchmark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f194f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_actualvspred = pd.DataFrame(columns = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "63fc29bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>formally diagnose autism spectrum disorder sign symptom lead get assess diagnosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moral lesson advice father male figure teach instrument journey life matter unorthodox may edit fundamental lesson learn dad unsaid rather say man word would speak something say two important thing show want achieve anything life must discipline resilient face adversity edit fundamental advice father give believe make mention never use people success metric measure success life progress life pace succumb pressure society environment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continued date person everyone tell break</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>favorite nonsexual activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stuck mile away boyfriends girlfriend pandemic meet together month two manage keep relationship go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>vanilla sex woman sometimes feel inadequate relation kinky porn culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>call hair bun language hair bun english spanish always call tomate mean tomato start call hair tomato english instead say bun cuz make laugh lol language call edit thanks everyone answer never expect many reply lol love learn language read reply much fun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>realize grown apart old friend cope loss someone post askwomen since man go thought ask fellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>marry co habitating work come home housework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>pick struggle mental health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                     descr\n",
       "0                                                                                                                                                                                                                                                                                                                                                                        formally diagnose autism spectrum disorder sign symptom lead get assess diagnosed\n",
       "1     moral lesson advice father male figure teach instrument journey life matter unorthodox may edit fundamental lesson learn dad unsaid rather say man word would speak something say two important thing show want achieve anything life must discipline resilient face adversity edit fundamental advice father give believe make mention never use people success metric measure success life progress life pace succumb pressure society environment\n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                continued date person everyone tell break\n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                              favorite nonsexual activity\n",
       "4                                                                                                                                                                                                                                                                                                                                                       stuck mile away boyfriends girlfriend pandemic meet together month two manage keep relationship go\n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...\n",
       "495                                                                                                                                                                                                                                                                                                                                                                                vanilla sex woman sometimes feel inadequate relation kinky porn culture\n",
       "496                                                                                                                                                                                         call hair bun language hair bun english spanish always call tomate mean tomato start call hair tomato english instead say bun cuz make laugh lol language call edit thanks everyone answer never expect many reply lol love learn language read reply much fun\n",
       "497                                                                                                                                                                                                                                                                                                                                                         realize grown apart old friend cope loss someone post askwomen since man go thought ask fellow\n",
       "498                                                                                                                                                                                                                                                                                                                                                                                                           marry co habitating work come home housework\n",
       "499                                                                                                                                                                                                                                                                                                                                                                                                                            pick struggle mental health\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_actualvspred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "36a5b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_actualvspred['descr'] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "931c3f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_actualvspred['actual'] = y_test.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "066ad719",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_actualvspred['predicted'] = lrtvecgs_bestmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "833fe565",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongly_classified_data = lr_actualvspred[lr_actualvspred['actual']!=lr_actualvspred['predicted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "6133bf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descr</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continued date person everyone tell break</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>favorite nonsexual activity</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stuck mile away boyfriends girlfriend pandemic meet together month two manage keep relationship go</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boundary non negotiable</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pratice self love see attractive without validation external source</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>get back together someone cheat give second chance work</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>play rpgs dm gm help safe feel welcome table especially look advice regard game player might know everyone anyone except gm table edit want thank everyone comment helpful</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>stop go gym covid make gain want gain covid belly joke</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>AskWomen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>valentine day mega thread check thing gift food plan valentine day order avoid sea valentine galentine post one mega thread thread rule advice gift relax ask away also obviously ask relationship stuff monday look advice make sure descriptive succinct well information give good answer receive suggest sort new see well new stuff</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>vanilla sex woman sometimes feel inadequate relation kinky porn culture</td>\n",
       "      <td>AskWomen</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                         descr  \\\n",
       "2                                                                                                                                                                                                                                                                                                    continued date person everyone tell break   \n",
       "3                                                                                                                                                                                                                                                                                                                  favorite nonsexual activity   \n",
       "4                                                                                                                                                                                                                                           stuck mile away boyfriends girlfriend pandemic meet together month two manage keep relationship go   \n",
       "5                                                                                                                                                                                                                                                                                                                      boundary non negotiable   \n",
       "6                                                                                                                                                                                                                                                                          pratice self love see attractive without validation external source   \n",
       "..                                                                                                                                                                                                                                                                                                                                         ...   \n",
       "483                                                                                                                                                                                                                                                                                    get back together someone cheat give second chance work   \n",
       "485                                                                                                                                                                 play rpgs dm gm help safe feel welcome table especially look advice regard game player might know everyone anyone except gm table edit want thank everyone comment helpful   \n",
       "491                                                                                                                                                                                                                                                                                     stop go gym covid make gain want gain covid belly joke   \n",
       "493   valentine day mega thread check thing gift food plan valentine day order avoid sea valentine galentine post one mega thread thread rule advice gift relax ask away also obviously ask relationship stuff monday look advice make sure descriptive succinct well information give good answer receive suggest sort new see well new stuff   \n",
       "495                                                                                                                                                                                                                                                                    vanilla sex woman sometimes feel inadequate relation kinky porn culture   \n",
       "\n",
       "       actual predicted  \n",
       "2    AskWomen    AskMen  \n",
       "3      AskMen  AskWomen  \n",
       "4    AskWomen    AskMen  \n",
       "5      AskMen  AskWomen  \n",
       "6      AskMen  AskWomen  \n",
       "..        ...       ...  \n",
       "483  AskWomen    AskMen  \n",
       "485  AskWomen    AskMen  \n",
       "491    AskMen  AskWomen  \n",
       "493  AskWomen    AskMen  \n",
       "495  AskWomen    AskMen  \n",
       "\n",
       "[139 rows x 3 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrongly_classified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c25ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6662e7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc0519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ca02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30381645",
   "metadata": {},
   "source": [
    "#### Decision Tree Cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f3defa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvecpipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('dt', DecisionTreeClassifier(random_state= 42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "175fcf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('dt', DecisionTreeClassifier(random_state=42))],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'dt': DecisionTreeClassifier(random_state=42),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'dt__ccp_alpha': 0.0,\n",
       " 'dt__class_weight': None,\n",
       " 'dt__criterion': 'gini',\n",
       " 'dt__max_depth': None,\n",
       " 'dt__max_features': None,\n",
       " 'dt__max_leaf_nodes': None,\n",
       " 'dt__min_impurity_decrease': 0.0,\n",
       " 'dt__min_impurity_split': None,\n",
       " 'dt__min_samples_leaf': 1,\n",
       " 'dt__min_samples_split': 2,\n",
       " 'dt__min_weight_fraction_leaf': 0.0,\n",
       " 'dt__random_state': 42,\n",
       " 'dt__splitter': 'best'}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcvecpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c70ae5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvecpipe_params={ 'cvec__max_df': [0.3, 0.5],\n",
    "                    'cvec__max_features': [1000, 2000, 3000],\n",
    "                    'cvec__min_df': [4, 5, 6],\n",
    "                    'cvec__ngram_range': [(1, 1), (1, 2)],\n",
    "#                     'dt__ccp_alpha': [0, 0.5, 1.0],\n",
    "                    'dt__max_depth': [None, 10, 20],\n",
    "                    'dt__min_samples_split': [2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "98de76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvecgs = GridSearchCV(\n",
    "    dtcvecpipe, # what object are we optimizing?\n",
    "    param_grid = dtcvecpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ec8967e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('dt',\n",
       "                                        DecisionTreeClassifier(random_state=42))]),\n",
       "             param_grid={'cvec__max_df': [0.3, 0.5],\n",
       "                         'cvec__max_features': [1000, 2000, 3000],\n",
       "                         'cvec__min_df': [4, 5, 6],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'dt__ccp_alpha': [0, 0.5, 1.0],\n",
       "                         'dt__max_depth': [3, 5, 10],\n",
       "                         'dt__min_samples_split': [2, 3, 4]})"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcvecgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "edafc71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.3,\n",
       " 'cvec__max_features': 1000,\n",
       " 'cvec__min_df': 6,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'dt__ccp_alpha': 0,\n",
       " 'dt__max_depth': 10,\n",
       " 'dt__min_samples_split': 4}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcvecgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8f1436dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6826666666666668"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcvecgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b6b31983",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtcvecgs_bestmodel = dtcvecgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "576b8f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.772"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcvecgs_bestmodel.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "60634d59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.636"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtcvecgs_bestmodel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99916543",
   "metadata": {},
   "source": [
    "#### Decision Tree Tfid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cb6bb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dttvecpipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e67c11e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer()), ('dt', DecisionTreeClassifier())],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'dt': DecisionTreeClassifier(),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'dt__ccp_alpha': 0.0,\n",
       " 'dt__class_weight': None,\n",
       " 'dt__criterion': 'gini',\n",
       " 'dt__max_depth': None,\n",
       " 'dt__max_features': None,\n",
       " 'dt__max_leaf_nodes': None,\n",
       " 'dt__min_impurity_decrease': 0.0,\n",
       " 'dt__min_impurity_split': None,\n",
       " 'dt__min_samples_leaf': 1,\n",
       " 'dt__min_samples_split': 2,\n",
       " 'dt__min_weight_fraction_leaf': 0.0,\n",
       " 'dt__presort': 'deprecated',\n",
       " 'dt__random_state': None,\n",
       " 'dt__splitter': 'best'}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dttvecpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "927e1637",
   "metadata": {},
   "outputs": [],
   "source": [
    "dttvecpipe_params={ 'tvec__max_df': [0.25, 0.3, 0.5],\n",
    "                    'tvec__max_features': [2000, 3000, 4000],\n",
    "                    'tvec__min_df': [4, 5, 6],\n",
    "                    'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "                    'dt__ccp_alpha': [0, 1],\n",
    "                    'dt__max_depth': [5, 6, 7],\n",
    "                    'dt__min_samples_split': [2, 3, 4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f52d97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dttvecgs = GridSearchCV(\n",
    "    dttvecpipe, # what object are we optimizing?\n",
    "    param_grid = dttvecpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "873bc7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('dt', DecisionTreeClassifier())]),\n",
       "             param_grid={'dt__ccp_alpha': [0, 1], 'dt__max_depth': [5, 6, 7],\n",
       "                         'dt__min_samples_split': [2, 3],\n",
       "                         'tvec__max_df': [0.25, 0.3, 0.5],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [4, 5, 6],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dttvecgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6282eddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__ccp_alpha': 0,\n",
       " 'dt__max_depth': 6,\n",
       " 'dt__min_samples_split': 3,\n",
       " 'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 5,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dttvecgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2a4ef55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dttvecgs_bestmodel = dttvecgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f8e5fb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7466666666666667"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dttvecgs_bestmodel.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7dafc861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dttvecgs_bestmodel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032ab647",
   "metadata": {},
   "source": [
    "#### Decision Tree Tfid Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "19aa71e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagtvecpipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),\n",
    "    ('bag', BaggingClassifier(DecisionTreeClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "e1fe0119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer()),\n",
       "  ('bag', BaggingClassifier(base_estimator=DecisionTreeClassifier()))],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'bag': BaggingClassifier(base_estimator=DecisionTreeClassifier()),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'bag__base_estimator__ccp_alpha': 0.0,\n",
       " 'bag__base_estimator__class_weight': None,\n",
       " 'bag__base_estimator__criterion': 'gini',\n",
       " 'bag__base_estimator__max_depth': None,\n",
       " 'bag__base_estimator__max_features': None,\n",
       " 'bag__base_estimator__max_leaf_nodes': None,\n",
       " 'bag__base_estimator__min_impurity_decrease': 0.0,\n",
       " 'bag__base_estimator__min_impurity_split': None,\n",
       " 'bag__base_estimator__min_samples_leaf': 1,\n",
       " 'bag__base_estimator__min_samples_split': 2,\n",
       " 'bag__base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'bag__base_estimator__presort': 'deprecated',\n",
       " 'bag__base_estimator__random_state': None,\n",
       " 'bag__base_estimator__splitter': 'best',\n",
       " 'bag__base_estimator': DecisionTreeClassifier(),\n",
       " 'bag__bootstrap': True,\n",
       " 'bag__bootstrap_features': False,\n",
       " 'bag__max_features': 1.0,\n",
       " 'bag__max_samples': 1.0,\n",
       " 'bag__n_estimators': 10,\n",
       " 'bag__n_jobs': None,\n",
       " 'bag__oob_score': False,\n",
       " 'bag__random_state': None,\n",
       " 'bag__verbose': 0,\n",
       " 'bag__warm_start': False}"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagtvecpipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "148c8770",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagtvecpipe_params={'tvec__max_df': [0.25, 0.3, 0.5],\n",
    "                    'tvec__max_features': [2000, 3000, 4000],\n",
    "                    'tvec__min_df': [4, 5, 6],\n",
    "                    'tvec__ngram_range': [(1, 1), (1, 2)],\n",
    "                    'bag__base_estimator__ccp_alpha': [0, 1],\n",
    "                    'bag__base_estimator__max_depth': [5, 6, 7],\n",
    "                    'bag__base_estimator__min_samples_split': [2, 3, 4],\n",
    "                    'bag__n_estimators': [30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "e3eafd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagtvecgs = GridSearchCV(\n",
    "    bagtvecpipe, # what object are we optimizing?\n",
    "    param_grid = bagtvecpipe_params,\n",
    "    cv=5) # what parameters values are we searching) # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "c9f1c07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tvec', TfidfVectorizer()),\n",
       "                                       ('bag',\n",
       "                                        BaggingClassifier(base_estimator=DecisionTreeClassifier()))]),\n",
       "             param_grid={'bag__base_estimator__ccp_alpha': [0, 1],\n",
       "                         'bag__base_estimator__max_depth': [5, 6, 7],\n",
       "                         'bag__base_estimator__min_samples_split': [2, 3, 4],\n",
       "                         'bag__n_estimators': [10, 20, 30],\n",
       "                         'tvec__max_df': [0.25, 0.3, 0.5],\n",
       "                         'tvec__max_features': [2000, 3000, 4000],\n",
       "                         'tvec__min_df': [4, 5, 6],\n",
       "                         'tvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagtvecgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "41db35d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__base_estimator__ccp_alpha': 0,\n",
       " 'bag__base_estimator__max_depth': 7,\n",
       " 'bag__base_estimator__min_samples_split': 4,\n",
       " 'bag__n_estimators': 30,\n",
       " 'tvec__max_df': 0.3,\n",
       " 'tvec__max_features': 3000,\n",
       " 'tvec__min_df': 5,\n",
       " 'tvec__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagtvecgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ad6f9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagtvecgs_bestmodel = bagtvecgs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a6238f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8006666666666666"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagtvecgs_bestmodel.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d00f0766",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.686"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagtvecgs_bestmodel.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f55f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ecba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b1c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcca09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34402a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c5f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a40d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe115c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f539d263",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68667165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90cafb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a9d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09acb9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e769ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d5e422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c669a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead258a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98e637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a275a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9396edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
